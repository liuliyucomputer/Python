# Pythonæ–°å…´æŠ€æœ¯ä¸å‰æ²¿é¢†åŸŸæ–‡æ¡£

## 1. é‡å­è®¡ç®—ä¸é‡å­ç¼–ç¨‹

### 1.1 é‡å­è®¡ç®—åŸºç¡€æ¦‚å¿µ
**[æ ‡è¯†: QUANTUM-COMPUTING-001]**

é‡å­è®¡ç®—æ˜¯åˆ©ç”¨é‡å­åŠ›å­¦åŸç†è¿›è¡Œä¿¡æ¯å¤„ç†çš„æ–°å‹è®¡ç®—æ–¹å¼ï¼Œå…·æœ‰è§£å†³æŸäº›ç»å…¸è®¡ç®—æœºéš¾ä»¥å¤„ç†çš„é—®é¢˜çš„æ½œåŠ›ã€‚

```python
# é‡å­è®¡ç®—åŸºç¡€æ¦‚å¿µç¤ºä¾‹

# é‡å­æ¯”ç‰¹ï¼ˆQubitï¼‰çš„æ¦‚å¿µç†è§£
# ç»å…¸æ¯”ç‰¹: 0 æˆ– 1
# é‡å­æ¯”ç‰¹: å¯ä»¥åŒæ—¶å¤„äº0å’Œ1çš„å åŠ æ€

# é‡å­çº ç¼ ï¼ˆEntanglementï¼‰çš„ç†è§£
# ä¸¤ä¸ªæˆ–å¤šä¸ªé‡å­æ¯”ç‰¹ä¹‹é—´çš„å¼ºç›¸å…³æ€§

# é‡å­é—¨æ“ä½œçš„åŸºæœ¬ç±»å‹
# - å•é‡å­æ¯”ç‰¹é—¨: Pauli-X, Pauli-Y, Pauli-Z, Hadamardç­‰
# - å¤šé‡å­æ¯”ç‰¹é—¨: CNOT, Toffoliç­‰
```

### 1.2 Pythoné‡å­è®¡ç®—æ¡†æ¶
**[æ ‡è¯†: QUANTUM-FRAMEWORK-001]**

ä½¿ç”¨Pythonè¿›è¡Œé‡å­è®¡ç®—å¼€å‘çš„ä¸»æµæ¡†æ¶å’Œåº“ã€‚

```python
# Qiskit (IBMçš„é‡å­è®¡ç®—æ¡†æ¶)

# å®‰è£…: pip install qiskit qiskit-visualization

from qiskit import QuantumCircuit, transpile, Aer, IBMQ
from qiskit.visualization import plot_histogram

# åˆ›å»ºä¸€ä¸ªç®€å•çš„é‡å­ç”µè·¯ï¼ˆBellæ€ï¼‰
qc = QuantumCircuit(2, 2)
qc.h(0)  # Hadamardé—¨ä½œç”¨åœ¨ç¬¬ä¸€ä¸ªé‡å­æ¯”ç‰¹ä¸Š
qc.cx(0, 1)  # CNOTé—¨ï¼Œæ§åˆ¶æ¯”ç‰¹æ˜¯0ï¼Œç›®æ ‡æ¯”ç‰¹æ˜¯1
qc.measure([0, 1], [0, 1])  # æµ‹é‡é‡å­æ¯”ç‰¹å¹¶æ˜ å°„åˆ°ç»å…¸æ¯”ç‰¹

# ç»˜åˆ¶ç”µè·¯
print("é‡å­ç”µè·¯å›¾:")
print(qc.draw())

# ä½¿ç”¨æ¨¡æ‹Ÿå™¨è¿è¡Œç”µè·¯
simulator = Aer.get_backend('qasm_simulator')
compiled_circuit = transpile(qc, simulator)
job = simulator.run(compiled_circuit, shots=1000)
result = job.result()
counts = result.get_counts(qc)

# ç»˜åˆ¶ç»“æœç›´æ–¹å›¾
print("\næµ‹é‡ç»“æœ:")
print(counts)

# ç¤ºä¾‹ï¼šQAOAç®—æ³•ï¼ˆé‡å­è¿‘ä¼¼ä¼˜åŒ–ç®—æ³•ï¼‰è§£å†³æœ€å¤§å‰²é—®é¢˜

# PennyLaneï¼ˆè·¨å¹³å°é‡å­è®¡ç®—æ¡†æ¶ï¼‰

# å®‰è£…: pip install pennylane pennylane-qiskit pennylane-lightning

import pennylane as qml
from pennylane import numpy as np

# åˆ›å»ºé‡å­è®¾å¤‡
dev = qml.device("default.qubit", wires=2)

# å®šä¹‰é‡å­ç”µè·¯ï¼ˆé‡å­èŠ‚ç‚¹ï¼‰
@qml.qnode(dev)

def circuit(phi):
    # åˆå§‹åŒ–
    qml.Hadamard(wires=0)
    qml.CNOT(wires=[0, 1])
    # å‚æ•°åŒ–æ—‹è½¬é—¨
    qml.RX(phi, wires=0)
    # æµ‹é‡
    return qml.expval(qml.PauliZ(0))

# ä¼˜åŒ–å‚æ•°
phi = 0.5
result = circuit(phi)
print(f"\nPennyLaneç”µè·¯ç»“æœ: {result}")

# Cirq (Googleçš„é‡å­è®¡ç®—æ¡†æ¶)

# å®‰è£…: pip install cirq

import cirq

# åˆ›å»ºé‡å­æ¯”ç‰¹
q0, q1 = cirq.LineQubit.range(2)

# åˆ›å»ºç”µè·¯
circuit = cirq.Circuit()
# æ·»åŠ é—¨
circuit.append(cirq.H(q0))  # Hadamardé—¨
circuit.append(cirq.CNOT(q0, q1))  # CNOTé—¨
circuit.append(cirq.measure(q0, q1, key='result'))  # æµ‹é‡

print("\nCirqç”µè·¯å›¾:")
print(circuit)

# æ¨¡æ‹Ÿè¿è¡Œ
 simulator = cirq.Simulator()
result = simulator.run(circuit, repetitions=1000)
print("\nCirqæµ‹é‡ç»“æœ:")
print(result.histogram(key='result'))
```

### 1.3 é‡å­ç®—æ³•ä¸åº”ç”¨åœºæ™¯
**[æ ‡è¯†: QUANTUM-ALGORITHM-001]**

æ¢ç´¢Pythonå®ç°çš„é‡å­ç®—æ³•åŠå…¶åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨ã€‚

```python
# é‡å­å‚…é‡Œå¶å˜æ¢ï¼ˆQFTï¼‰

from qiskit import QuantumCircuit

def qft_rotations(circuit, n):
    """QFTç®—æ³•çš„æ—‹è½¬éƒ¨åˆ†"""
    if n == 0:  # åŸºæœ¬æƒ…å†µ
        return circuit
    n -= 1  # ç´¢å¼•ä»0å¼€å§‹
    circuit.h(n)
    for qubit in range(n):
        circuit.cp(np.pi/2**(n-qubit), qubit, n)
    # é€’å½’åº”ç”¨åˆ°å‰©ä½™çš„é‡å­æ¯”ç‰¹
    qft_rotations(circuit, n)

def swap_registers(circuit, n):
    """äº¤æ¢å¯„å­˜å™¨ä»¥å®ŒæˆQFT"""
    for qubit in range(n//2):
        circuit.swap(qubit, n-qubit-1)
    return circuit

def qft(circuit, n):
    """åˆ›å»ºné‡å­æ¯”ç‰¹çš„QFT"""
    qft_rotations(circuit, n)
    swap_registers(circuit, n)
    return circuit

# åˆ›å»ºQFTç”µè·¯
n = 3
qft_circuit = QuantumCircuit(n)
qft(qft_circuit, n)
print("\né‡å­å‚…é‡Œå¶å˜æ¢ç”µè·¯å›¾:")
print(qft_circuit.draw())

# Shorç®—æ³•ï¼ˆç”¨äºå› æ•°åˆ†è§£ï¼‰æ€æƒ³å±•ç¤º
"""
Shorç®—æ³•çš„ä¸»è¦æ­¥éª¤ï¼š
1. é€‰æ‹©ä¸€ä¸ªéšæœºæ•°a < N
2. è®¡ç®—gcd(a, N)ï¼Œå¦‚æœä¸ç­‰äº1ï¼Œåˆ™æ‰¾åˆ°ä¸€ä¸ªå› æ•°
3. ä½¿ç”¨é‡å­å‚…é‡Œå¶å˜æ¢å¯»æ‰¾a^x mod Nçš„å‘¨æœŸr
4. å¦‚æœrä¸ºå¶æ•°ä¸”a^(r/2) â‰  -1 mod Nï¼Œåˆ™gcd(a^(r/2) Â± 1, N)å¯èƒ½æ˜¯Nçš„å› æ•°
"""

# Groveræœç´¢ç®—æ³•

from qiskit import Aer, execute

def create_oracle(n, marked_states):
    """åˆ›å»ºGroveræœç´¢çš„oracle"""
    qc = QuantumCircuit(n)
    # å¯¹æ¯ä¸ªæ ‡è®°çŠ¶æ€æ·»åŠ ç›¸ä½ç¿»è½¬
    for state in marked_states:
        # å°†äºŒè¿›åˆ¶çŠ¶æ€è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•
        binary_state = format(state, '0' + str(n) + 'b')[::-1]  # åè½¬ä»¥ä¾¿å…ˆå¤„ç†ä½ä½
        
        # æ·»åŠ Xé—¨åˆ°äºŒè¿›åˆ¶çŠ¶æ€ä¸­ä¸º0çš„ä½ç½®
        for i in range(n):
            if binary_state[i] == '0':
                qc.x(i)
        
        # æ·»åŠ å¤šæ§Zé—¨
        qc.h(n-1)
        qc.mcx(list(range(n-1)), n-1)  # å¤šæ§Xé—¨ä½œä¸ºZé—¨ä½¿ç”¨
        qc.h(n-1)
        
        # æ’¤é”€Xé—¨
        for i in range(n):
            if binary_state[i] == '0':
                qc.x(i)
    
    return qc

def create_diffusion(n):
    """åˆ›å»ºGroveræœç´¢çš„æ‰©æ•£ç®—å­"""
    qc = QuantumCircuit(n)
    # åº”ç”¨Hé—¨åˆ°æ‰€æœ‰é‡å­æ¯”ç‰¹
    for qubit in range(n):
        qc.h(qubit)
    # åº”ç”¨Xé—¨åˆ°æ‰€æœ‰é‡å­æ¯”ç‰¹
    for qubit in range(n):
        qc.x(qubit)
    # åº”ç”¨å¤šæ§Zé—¨
    qc.h(n-1)
    qc.mcx(list(range(n-1)), n-1)
    qc.h(n-1)
    # åº”ç”¨Xé—¨åˆ°æ‰€æœ‰é‡å­æ¯”ç‰¹
    for qubit in range(n):
        qc.x(qubit)
    # åº”ç”¨Hé—¨åˆ°æ‰€æœ‰é‡å­æ¯”ç‰¹
    for qubit in range(n):
        qc.h(qubit)
    return qc

def grover_algorithm(n, marked_states, iterations):
    """å®ç°Groveræœç´¢ç®—æ³•"""
    # åˆ›å»ºç”µè·¯
    qc = QuantumCircuit(n, n)
    
    # åˆå§‹åŒ–å åŠ æ€
    for qubit in range(n):
        qc.h(qubit)
    
    # åˆ›å»ºoracleå’Œdiffusionç®—å­
    oracle = create_oracle(n, marked_states)
    diffusion = create_diffusion(n)
    
    # é‡å¤Groverè¿­ä»£
    for _ in range(iterations):
        qc.compose(oracle, inplace=True)
        qc.compose(diffusion, inplace=True)
    
    # æµ‹é‡
    qc.measure(list(range(n)), list(range(n)))
    
    return qc

# ç¤ºä¾‹ï¼šåœ¨3é‡å­æ¯”ç‰¹ç³»ç»Ÿä¸­æœç´¢çŠ¶æ€|101âŸ©
n = 3
marked_states = [5]  # |101âŸ©å¯¹åº”çš„åè¿›åˆ¶æ˜¯5
iterations = 1  # è¿­ä»£æ¬¡æ•° ~Ï€/4*sqrt(N/M)

grover_circuit = grover_algorithm(n, marked_states, iterations)
print("\nGroveræœç´¢ç®—æ³•ç”µè·¯å›¾:")
print(grover_circuit.draw())

# è¿è¡Œæ¨¡æ‹Ÿ
simulator = Aer.get_backend('qasm_simulator')
job = execute(grover_circuit, simulator, shots=1000)
result = job.result()
counts = result.get_counts()
print("\nGroveræœç´¢ç»“æœ:")
print(counts)

# é‡å­æœºå™¨å­¦ä¹ åº”ç”¨ç¤ºä¾‹

# å®‰è£…: pip install pennylane pennylane-qiskit scikit-learn

import pennylane as qml
from pennylane import numpy as np
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# åˆ›å»ºé‡å­è®¾å¤‡
dev = qml.device("default.qubit", wires=2)

# å®šä¹‰é‡å­ç”µè·¯ï¼ˆé‡å­ç¥ç»ç½‘ç»œï¼‰
@qml.qnode(dev)
def qnn_circuit(weights, x):
    # æ•°æ®ç¼–ç 
    qml.RX(x[0], wires=0)
    qml.RY(x[1], wires=0)
    qml.CNOT(wires=[0, 1])
    
    # å‚æ•°åŒ–å±‚
    qml.Rot(weights[0, 0], weights[0, 1], weights[0, 2], wires=0)
    qml.Rot(weights[1, 0], weights[1, 1], weights[1, 2], wires=1)
    
    # æµ‹é‡
    return qml.expval(qml.PauliZ(1))

# å®šä¹‰æˆæœ¬å‡½æ•°
def cost_function(weights, X, y):
    predictions = [qnn_circuit(weights, x) for x in X]
    return np.mean((predictions - y) ** 2)

# å‡†å¤‡æ•°æ®
X, y = make_moons(n_samples=100, noise=0.1, random_state=42)
y = np.where(y == 0, -1, 1)  # å°†0-1æ ‡ç­¾è½¬æ¢ä¸º-1-1
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# åˆå§‹åŒ–æƒé‡
np.random.seed(42)
weights = np.random.random((2, 3))

# ä¼˜åŒ–å™¨
opt = qml.GradientDescentOptimizer(stepsize=0.1)

# è®­ç»ƒ
steps = 100
for i in range(steps):
    weights = opt.step(lambda w: cost_function(w, X_train, y_train), weights)
    if (i + 1) % 10 == 0:
        cost = cost_function(weights, X_train, y_train)
        print(f"æ­¥éª¤ {i+1}/{steps}, æˆæœ¬: {cost:.4f}")

# è¯„ä¼°æ¨¡å‹
def predict(weights, x):
    return np.sign(qnn_circuit(weights, x))

y_pred = [predict(weights, x) for x in X_test]
accuracy = np.mean(y_pred == y_test)
print(f"\næµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f}")
```

## 2. è¾¹ç¼˜è®¡ç®—ä¸ç‰©è”ç½‘

### 2.1 è¾¹ç¼˜AIä¸è½»é‡çº§æœºå™¨å­¦ä¹ 
**[æ ‡è¯†: EDGE-AI-001]**

åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²Pythonè½»é‡çº§æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

```python
# ä½¿ç”¨TensorFlow Liteè¿›è¡Œæ¨¡å‹é‡åŒ–å’Œè¾¹ç¼˜éƒ¨ç½²

# å®‰è£…: pip install tensorflow

import tensorflow as tf
import numpy as np

# åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# ç¼–è¯‘æ¨¡å‹
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# ç”Ÿæˆè™šæ‹Ÿæ•°æ®
X_train = np.random.random((1000, 10))
y_train = np.random.randint(0, 2, (1000, 1))

# è®­ç»ƒæ¨¡å‹
model.fit(X_train, y_train, epochs=5, batch_size=32)

# ä¿å­˜åŸå§‹æ¨¡å‹
model.save('original_model.h5')

# è½¬æ¢ä¸ºTFLiteæ¨¡å‹
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# å¯ç”¨æ•´æ•°é‡åŒ–
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# ä½¿ç”¨ä»£è¡¨æ€§æ•°æ®é›†è¿›è¡Œé‡åŒ–
# åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨æä¾›ä»£è¡¨æ€§æ•°æ®
def representative_data_gen():
    for i in range(50):
        yield [X_train[i:i+1].astype(np.float32)]

# è®¾ç½®ä»£è¡¨æ€§æ•°æ®é›†
converter.representative_dataset = representative_data_gen

# è®¾ç½®æ¨ç†è¾“å…¥è¾“å‡ºçš„ç±»å‹ï¼ˆå¿…é¡»æ˜¯é‡åŒ–æ¨¡å‹ï¼‰
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8

# è½¬æ¢æ¨¡å‹
tflite_quant_model = converter.convert()

# ä¿å­˜TFLiteæ¨¡å‹
with open('quantized_model.tflite', 'wb') as f:
    f.write(tflite_quant_model)

print("åŸå§‹æ¨¡å‹å¤§å°:", len(tf.io.read_file('original_model.h5')) / 1024, "KB")
print("é‡åŒ–æ¨¡å‹å¤§å°:", len(tflite_quant_model) / 1024, "KB")

# ä½¿ç”¨ONNX Runtimeè¿›è¡Œè·¨å¹³å°éƒ¨ç½²

# å®‰è£…: pip install onnx onnxruntime

import onnx
from onnx import numpy_helper
import onnxruntime as rt

# è½¬æ¢ä¸ºONNXæ ¼å¼
import tf2onnx

# è½¬æ¢æ¨¡å‹
onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=[tf.TensorSpec(shape=[None, 10], dtype=tf.float32, name='input')], opset=13)

# ä¿å­˜ONNXæ¨¡å‹
with open('model.onnx', 'wb') as f:
    f.write(onnx_model.SerializeToString())

print("ONNXæ¨¡å‹å¤§å°:", len(onnx_model.SerializeToString()) / 1024, "KB")

# ä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç†
sess = rt.InferenceSession('model.onnx')
input_name = sess.get_inputs()[0].name
output_name = sess.get_outputs()[0].name

# æµ‹è¯•æ¨ç†
input_data = np.random.random((1, 10)).astype(np.float32)
result = sess.run([output_name], {input_name: input_data})
print("ONNXæ¨ç†ç»“æœ:", result)

# ä½¿ç”¨PyTorch Mobileè¿›è¡Œæ¨¡å‹ä¼˜åŒ–

# å®‰è£…: pip install torch torchvision

import torch
import torch.nn as nn
import torch.optim as optim

# å®šä¹‰PyTorchæ¨¡å‹
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(10, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.sigmoid(self.fc3(x))
        return x

# åˆå§‹åŒ–æ¨¡å‹
pytorch_model = SimpleModel()

# ä¿å­˜æ¨¡å‹
torch.save(pytorch_model.state_dict(), 'pytorch_model.pth')

# è½¬æ¢ä¸ºTorchScriptæ ¼å¼
scripted_model = torch.jit.script(pytorch_model)
scripted_model.save('scripted_model.pt')

# æ¨¡å‹é‡åŒ–ï¼ˆåŠ¨æ€é‡åŒ–ï¼‰
quantized_model = torch.quantization.quantize_dynamic(
    pytorch_model,
    {nn.Linear},
    dtype=torch.qint8
)

# ä¿å­˜é‡åŒ–æ¨¡å‹
torch.jit.save(torch.jit.script(quantized_model), 'quantized_pytorch_model.pt')

print("PyTorchæ¨¡å‹é‡åŒ–å®Œæˆ")

# è¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ¨ç†ä¼˜åŒ–æŠ€æœ¯

# 1. æ¨¡å‹å‰ªæç¤ºä¾‹
"""
# å®‰è£…: pip install torch-pruning

import torch_pruning as tp

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = SimpleModel()

# å®šä¹‰å‰ªæç­–ç•¥
strategy = tp.strategy.L1Strategy()  # L1èŒƒæ•°ç­–ç•¥

# åˆå§‹åŒ–å‰ªæå™¨
pruner = tp.pruner.MagnitudePruner(
    model,
    [(model.fc1, 'weight')],  # è¦å‰ªæçš„å±‚å’Œå‚æ•°
    strategy=strategy,
    pruning_ratio=0.5,  # å‰ªæ50%çš„æƒé‡
)

# æ‰§è¡Œå‰ªæ
pruner.step()

# ä¿å­˜å‰ªæåçš„æ¨¡å‹
torch.jit.save(torch.jit.script(model), 'pruned_model.pt')
"""

# 2. çŸ¥è¯†è’¸é¦ç¤ºä¾‹

class StudentModel(nn.Module):
    def __init__(self):
        super(StudentModel, self).__init__()
        self.fc1 = nn.Linear(10, 32)  # æ›´å°çš„éšè—å±‚
        self.fc2 = nn.Linear(32, 1)  # ç›´æ¥è¾“å‡º
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.sigmoid(self.fc2(x))
        return x

# çŸ¥è¯†è’¸é¦æŸå¤±å‡½æ•°
def distillation_loss(student_logits, teacher_logits, target, T=2.0, alpha=0.5):
    # è½¯ç›®æ ‡æŸå¤±ï¼ˆKLæ•£åº¦ï¼‰
    soft_targets = nn.functional.softmax(teacher_logits / T, dim=1)
    soft_prob = nn.functional.log_softmax(student_logits / T, dim=1)
    soft_loss = nn.functional.kl_div(soft_prob, soft_targets, reduction='batchmean') * (T * T)
    
    # ç¡¬ç›®æ ‡æŸå¤±
    hard_loss = nn.functional.cross_entropy(student_logits, target)
    
    # ç»“åˆæŸå¤±
    return alpha * soft_loss + (1 - alpha) * hard_loss

print("çŸ¥è¯†è’¸é¦æ¨¡å‹å®šä¹‰å®Œæˆ")
```

### 2.2 ç‰©è”ç½‘æ•°æ®é‡‡é›†ä¸å¤„ç†
**[æ ‡è¯†: IoT-DATA-001]**

ä½¿ç”¨Pythonè¿›è¡Œç‰©è”ç½‘è®¾å¤‡æ•°æ®é‡‡é›†ã€ä¼ è¾“å’Œå¤„ç†çš„æœ€ä½³å®è·µã€‚

```python
# MQTTåè®®é€šä¿¡ç¤ºä¾‹

# å®‰è£…: pip install paho-mqtt

import paho.mqtt.client as mqtt
import time
import json
import random

# MQTTä»£ç†è®¾ç½®
MQTT_BROKER = "broker.hivemq.com"  # å…¬å…±MQTTä»£ç†
MQTT_PORT = 1883
MQTT_CLIENT_ID = "python_iot_publisher"
MQTT_USERNAME = "your_username"  # å¦‚æœéœ€è¦è®¤è¯
MQTT_PASSWORD = "your_password"  # å¦‚æœéœ€è¦è®¤è¯

# ä¸»é¢˜è®¾ç½®
MQTT_TOPIC_TEMPERATURE = "sensors/temperature"
MQTT_TOPIC_HUMIDITY = "sensors/humidity"
MQTT_TOPIC_DEVICE_STATUS = "devices/status"

# å‘å¸ƒè€…ä»£ç ç¤ºä¾‹

def on_connect_publisher(client, userdata, flags, rc):
    if rc == 0:
        print("å·²è¿æ¥åˆ°MQTTä»£ç†")
    else:
        print(f"è¿æ¥å¤±è´¥ï¼Œé”™è¯¯ä»£ç : {rc}")

# åˆ›å»ºMQTTå®¢æˆ·ç«¯
publisher = mqtt.Client(client_id=MQTT_CLIENT_ID)

# è®¾ç½®å›è°ƒå‡½æ•°
publisher.on_connect = on_connect_publisher

# è®¾ç½®è®¤è¯ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
# publisher.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)

# è¿æ¥åˆ°ä»£ç†
publisher.connect(MQTT_BROKER, MQTT_PORT, keepalive=60)

# å¯åŠ¨å¾ªç¯
publisher.loop_start()

# æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®å‘å¸ƒ
try:
    print("å¼€å§‹å‘å¸ƒä¼ æ„Ÿå™¨æ•°æ®ï¼ˆæŒ‰Ctrl+Cåœæ­¢ï¼‰")
    while True:
        # æ¨¡æ‹Ÿæ¸©åº¦æ•°æ®
        temperature_data = {
            "device_id": "temp_sensor_01",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "temperature": round(random.uniform(20.0, 30.0), 2),
            "unit": "Â°C"
        }
        
        # æ¨¡æ‹Ÿæ¹¿åº¦æ•°æ®
        humidity_data = {
            "device_id": "hum_sensor_01",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "humidity": round(random.uniform(30.0, 70.0), 2),
            "unit": "%"
        }
        
        # è®¾å¤‡çŠ¶æ€
        status_data = {
            "device_id": "device_01",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "status": "online",
            "battery": round(random.uniform(70.0, 100.0), 1)
        }
        
        # å‘å¸ƒæ¶ˆæ¯
        publisher.publish(MQTT_TOPIC_TEMPERATURE, json.dumps(temperature_data), qos=1)
        publisher.publish(MQTT_TOPIC_HUMIDITY, json.dumps(humidity_data), qos=1)
        publisher.publish(MQTT_TOPIC_DEVICE_STATUS, json.dumps(status_data), qos=1)
        
        print(f"å‘å¸ƒæ¸©åº¦æ•°æ®: {temperature_data['temperature']}Â°C")
        print(f"å‘å¸ƒæ¹¿åº¦æ•°æ®: {humidity_data['humidity']}%")
        print(f"å‘å¸ƒè®¾å¤‡çŠ¶æ€: {status_data['status']}, ç”µæ± : {status_data['battery']}%")
        
        # ç­‰å¾…5ç§’
        time.sleep(5)
except KeyboardInterrupt:
    print("åœæ­¢å‘å¸ƒ")
finally:
    # åœæ­¢å¾ªç¯å¹¶æ–­å¼€è¿æ¥
    publisher.loop_stop()
    publisher.disconnect()

# è®¢é˜…è€…ä»£ç ç¤ºä¾‹

# MQTTè®¢é˜…å®¢æˆ·ç«¯

MQTT_CLIENT_ID_SUBSCRIBER = "python_iot_subscriber"

# æ¥æ”¶æ¶ˆæ¯å›è°ƒå‡½æ•°
def on_message(client, userdata, msg):
    try:
        # è§£æJSONæ¶ˆæ¯
        payload = json.loads(msg.payload.decode())
        print(f"\næ”¶åˆ°ä¸»é¢˜: {msg.topic}")
        print(f"æ¶ˆæ¯å†…å®¹: {json.dumps(payload, indent=2)}")
        
        # æ ¹æ®ä¸»é¢˜è¿›è¡Œä¸åŒçš„å¤„ç†
        if msg.topic == MQTT_TOPIC_TEMPERATURE:
            # æ¸©åº¦æ•°æ®å¤„ç†é€»è¾‘
            temperature = payload["temperature"]
            if temperature > 28.0:
                print(f"è­¦å‘Š: æ¸©åº¦è¿‡é«˜ ({temperature}Â°C)")
        elif msg.topic == MQTT_TOPIC_HUMIDITY:
            # æ¹¿åº¦æ•°æ®å¤„ç†é€»è¾‘
            humidity = payload["humidity"]
            if humidity < 40.0:
                print(f"è­¦å‘Š: æ¹¿åº¦è¿‡ä½ ({humidity}%)")
        elif msg.topic == MQTT_TOPIC_DEVICE_STATUS:
            # è®¾å¤‡çŠ¶æ€å¤„ç†é€»è¾‘
            status = payload["status"]
            battery = payload["battery"]
            if battery < 80.0:
                print(f"è­¦å‘Š: è®¾å¤‡ç”µæ± ç”µé‡ä½ ({battery}%)")
                
    except Exception as e:
        print(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

def on_connect_subscriber(client, userdata, flags, rc):
    if rc == 0:
        print("å·²è¿æ¥åˆ°MQTTä»£ç†")
        # è®¢é˜…ä¸»é¢˜
        client.subscribe([
            (MQTT_TOPIC_TEMPERATURE, 1),
            (MQTT_TOPIC_HUMIDITY, 1),
            (MQTT_TOPIC_DEVICE_STATUS, 1)
        ])
        print("å·²è®¢é˜…æ‰€æœ‰ä¼ æ„Ÿå™¨ä¸»é¢˜")
    else:
        print(f"è¿æ¥å¤±è´¥ï¼Œé”™è¯¯ä»£ç : {rc}")

# åˆ›å»ºè®¢é˜…å®¢æˆ·ç«¯
subscriber = mqtt.Client(client_id=MQTT_CLIENT_ID_SUBSCRIBER)

# è®¾ç½®å›è°ƒå‡½æ•°
subscriber.on_connect = on_connect_subscriber
subscriber.on_message = on_message

# è®¾ç½®è®¤è¯ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
# subscriber.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)

# è¿æ¥åˆ°ä»£ç†
subscriber.connect(MQTT_BROKER, MQTT_PORT, keepalive=60)

# å¼€å§‹è®¢é˜…å¾ªç¯
print("å¼€å§‹æ¥æ”¶æ¶ˆæ¯ï¼ˆæŒ‰Ctrl+Cåœæ­¢ï¼‰")
try:
    subscriber.loop_forever()
except KeyboardInterrupt:
    print("åœæ­¢è®¢é˜…")
finally:
    subscriber.disconnect()

# ç‰©è”ç½‘æ•°æ®å¤„ç†ç®¡é“

# å®‰è£…: pip install pandas matplotlib paho-mqtt

import pandas as pd
import matplotlib.pyplot as plt
from collections import deque

# å®æ—¶æ•°æ®å¤„ç†ç±»
class IoTDataProcessor:
    def __init__(self, max_data_points=100):
        # ä½¿ç”¨åŒç«¯é˜Ÿåˆ—å­˜å‚¨æœ€è¿‘çš„æ•°æ®ç‚¹
        self.temperature_data = deque(maxlen=max_data_points)
        self.humidity_data = deque(maxlen=max_data_points)
        self.timestamps = deque(maxlen=max_data_points)
        
        # æ•°æ®ç»Ÿè®¡
        self.temp_stats = {
            "min": float('inf'),
            "max": float('-inf'),
            "avg": 0.0,
            "count": 0
        }
        
        self.humidity_stats = {
            "min": float('inf'),
            "max": float('-inf'),
            "avg": 0.0,
            "count": 0
        }
    
    def process_temperature(self, value, timestamp):
        """å¤„ç†æ¸©åº¦æ•°æ®"""
        # æ·»åŠ åˆ°é˜Ÿåˆ—
        self.temperature_data.append(value)
        self.timestamps.append(timestamp)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.temp_stats["count"] += 1
        self.temp_stats["min"] = min(self.temp_stats["min"], value)
        self.temp_stats["max"] = max(self.temp_stats["max"], value)
        # ç§»åŠ¨å¹³å‡è®¡ç®—
        self.temp_stats["avg"] = (
            (self.temp_stats["avg"] * (self.temp_stats["count"] - 1) + value) / 
            self.temp_stats["count"]
        )
        
        # ç®€å•å¼‚å¸¸æ£€æµ‹
        if value > 30.0 or value < 10.0:
            return f"å¼‚å¸¸: æ¸©åº¦å€¼ {value}Â°C è¶…å‡ºæ­£å¸¸èŒƒå›´"
        
        return None
    
    def process_humidity(self, value, timestamp):
        """å¤„ç†æ¹¿åº¦æ•°æ®"""
        # æ·»åŠ åˆ°é˜Ÿåˆ—
        self.humidity_data.append(value)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.humidity_stats["count"] += 1
        self.humidity_stats["min"] = min(self.humidity_stats["min"], value)
        self.humidity_stats["max"] = max(self.humidity_stats["max"], value)
        # ç§»åŠ¨å¹³å‡è®¡ç®—
        self.humidity_stats["avg"] = (
            (self.humidity_stats["avg"] * (self.humidity_stats["count"] - 1) + value) / 
            self.humidity_stats["count"]
        )
        
        # ç®€å•å¼‚å¸¸æ£€æµ‹
        if value > 90.0 or value < 10.0:
            return f"å¼‚å¸¸: æ¹¿åº¦å€¼ {value}% è¶…å‡ºæ­£å¸¸èŒƒå›´"
        
        return None
    
    def get_statistics(self):
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "temperature": self.temp_stats.copy(),
            "humidity": self.humidity_stats.copy(),
            "data_points": len(self.temperature_data)
        }
    
    def visualize_data(self, save_path=None):
        """å¯è§†åŒ–æœ€è¿‘çš„æ•°æ®"""
        if len(self.timestamps) < 2:
            print("æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•å¯è§†åŒ–")
            return
        
        # åˆ›å»ºæ•°æ®æ¡†
        df = pd.DataFrame({
            'timestamp': list(self.timestamps),
            'temperature': list(self.temperature_data),
            'humidity': list(self.humidity_data)
        })
        
        # è®¾ç½®æ—¶é—´æˆ³ä¸ºç´¢å¼•
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # åˆ›å»ºå›¾è¡¨
        fig, ax1 = plt.subplots(figsize=(12, 6))
        
        # ç»˜åˆ¶æ¸©åº¦
        ax1.set_xlabel('æ—¶é—´')
        ax1.set_ylabel('æ¸©åº¦ (Â°C)', color='tab:red')
        ax1.plot(df.index, df['temperature'], color='tab:red', marker='o', linestyle='-', markersize=4)
        ax1.tick_params(axis='y', labelcolor='tab:red')
        
        # åˆ›å»ºç¬¬äºŒä¸ªYè½´ç»˜åˆ¶æ¹¿åº¦
        ax2 = ax1.twinx()
        ax2.set_ylabel('æ¹¿åº¦ (%)', color='tab:blue')
        ax2.plot(df.index, df['humidity'], color='tab:blue', marker='s', linestyle='--', markersize=4)
        ax2.tick_params(axis='y', labelcolor='tab:blue')
        
        # è®¾ç½®æ ‡é¢˜
        plt.title('å®æ—¶ä¼ æ„Ÿå™¨æ•°æ®ç›‘æ§')
        
        # è°ƒæ•´å¸ƒå±€
        fig.tight_layout()
        
        # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾è¡¨
        if save_path:
            plt.savefig(save_path, dpi=300)
            print(f"å›¾è¡¨å·²ä¿å­˜åˆ° {save_path}")
        else:
            plt.show()

# ä½¿ç”¨ç¤ºä¾‹
# processor = IoTDataProcessor()
# for i in range(20):
#     temp = 25 + random.uniform(-2, 2)
#     humidity = 50 + random.uniform(-10, 10)
#     timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
#     
#     temp_alert = processor.process_temperature(temp, timestamp)
#     humidity_alert = processor.process_humidity(humidity, timestamp)
#     
#     if temp_alert:
#         print(temp_alert)
#     if humidity_alert:
#         print(humidity_alert)
#     
#     time.sleep(0.5)
# 
# # è·å–ç»Ÿè®¡ä¿¡æ¯
# stats = processor.get_statistics()
# print("\nç»Ÿè®¡ä¿¡æ¯:")
# print(json.dumps(stats, indent=2))
# 
# # å¯è§†åŒ–æ•°æ®
# processor.visualize_data("sensor_data.png")

# LoRaWANåè®®é€šä¿¡ç¤ºä¾‹ï¼ˆæ¨¡æ‹Ÿï¼‰

"""
# å®‰è£…: pip install pycryptodome

from Crypto.Cipher import AES
import base64
import struct

def generate_lorawan_payload(device_id, data):
    """æ¨¡æ‹Ÿç”ŸæˆLoRaWANåŠ å¯†æœ‰æ•ˆè½½è·"""
    # è¿™é‡Œä»…ä½œä¸ºç¤ºä¾‹ï¼Œå®é™…LoRaWANé€šä¿¡éœ€è¦å®Œæ•´çš„OTAAæˆ–ABPè®¤è¯
    # ä»¥åŠæ­£ç¡®çš„AESåŠ å¯†å’ŒMICè®¡ç®—
    
    # æ¨¡æ‹Ÿè®¾å¤‡åœ°å€
    dev_addr = bytes.fromhex("01234567")
    
    # æ¨¡æ‹ŸFCtrlå’ŒFCnt
    f_ctrl = 0x80  # ADRä½è®¾ç½®
    f_cnt = 123    # å¸§è®¡æ•°å™¨
    
    # æ•°æ®å†…å®¹ï¼ˆæ¸©åº¦å’Œæ¹¿åº¦ä½œä¸ºç¤ºä¾‹ï¼‰
    temp = int(data.get("temperature", 25) * 10)
    humidity = int(data.get("humidity", 50))
    
    # å°†æ•°æ®æ‰“åŒ…ä¸ºäºŒè¿›åˆ¶
    payload = struct.pack("!hB", temp, humidity)
    
    # æ¨¡æ‹ŸåŠ å¯†ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ­£ç¡®çš„AES-128åŠ å¯†ï¼‰
    # è¿™é‡Œä»…ä½œæ¼”ç¤º
    
    print(f"LoRaWANæ•°æ®åŒ…ç”Ÿæˆ:")
    print(f"  è®¾å¤‡ID: {device_id}")
    print(f"  è®¾å¤‡åœ°å€: {dev_addr.hex()}")
    print(f"  å¸§è®¡æ•°å™¨: {f_cnt}")
    print(f"  åŸå§‹æ•°æ®: {payload.hex()}")
    
    return {
        "dev_addr": dev_addr.hex(),
        "f_cnt": f_cnt,
        "payload": base64.b64encode(payload).decode(),
        "device_id": device_id
    }

# ä½¿ç”¨ç¤ºä¾‹
lorawan_data = generate_lorawan_payload(
    "lora_device_01",
    {"temperature": 26.5, "humidity": 62}
)
print(json.dumps(lorawan_data, indent=2))
"""
```

### 2.3 å®æ—¶æ•°æ®å¤„ç†ä¸è¾¹ç¼˜åˆ†æ
**[æ ‡è¯†: EDGE-ANALYTICS-001]**

åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶æ•°æ®åˆ†æå’Œå¤„ç†ç®—æ³•ã€‚

```python
# ä½¿ç”¨Numbaè¿›è¡Œå®æ—¶æ•°æ®å¤„ç†ä¼˜åŒ–

# å®‰è£…: pip install numba

import numpy as np
from numba import jit, njit, prange
import time

# ç”Ÿæˆæµ‹è¯•æ•°æ®
np.random.seed(42)
data = np.random.rand(1_000_000)

# ä¼ ç»ŸPythonå‡½æ•°
def calculate_moving_average_python(data, window_size):
    """ä½¿ç”¨Pythonæ ‡å‡†æ–¹æ³•è®¡ç®—ç§»åŠ¨å¹³å‡"""
    result = []
    for i in range(len(data)):
        if i < window_size - 1:
            # ä¸è¶³çª—å£å¤§å°æ—¶ï¼Œå–å·²æœ‰çš„æ•°æ®å¹³å‡å€¼
            window = data[:i+1]
        else:
            window = data[i-window_size+1:i+1]
        result.append(sum(window) / len(window))
    return np.array(result)

# ä½¿ç”¨NumPyä¼˜åŒ–çš„å‡½æ•°
def calculate_moving_average_numpy(data, window_size):
    """ä½¿ç”¨NumPyè®¡ç®—ç§»åŠ¨å¹³å‡"""
    # ä½¿ç”¨å·ç§¯æ–¹æ³•
    weights = np.ones(window_size) / window_size
    # å·ç§¯è®¡ç®—
    result = np.convolve(data, weights, mode='full')
    # è°ƒæ•´ç»“æœé•¿åº¦ä¸è¾“å…¥ç›¸åŒ
    return result[:len(data)]

# ä½¿ç”¨Numba JITä¼˜åŒ–çš„å‡½æ•°
@njit(parallel=False)
def calculate_moving_average_numba(data, window_size):
    """ä½¿ç”¨Numba JITä¼˜åŒ–è®¡ç®—ç§»åŠ¨å¹³å‡"""
    result = np.zeros_like(data)
    for i in range(len(data)):
        window_start = max(0, i - window_size + 1)
        window = data[window_start:i+1]
        result[i] = np.mean(window)
    return result

# ä½¿ç”¨Numbaå¹¶è¡Œä¼˜åŒ–çš„å‡½æ•°
@njit(parallel=True)
def calculate_moving_average_numba_parallel(data, window_size):
    """ä½¿ç”¨Numbaå¹¶è¡Œè®¡ç®—ç§»åŠ¨å¹³å‡"""
    result = np.zeros_like(data)
    # ä½¿ç”¨prangeè¿›è¡Œå¹¶è¡Œå¾ªç¯
    for i in prange(len(data)):
        window_start = max(0, i - window_size + 1)
        window = data[window_start:i+1]
        # æ‰‹åŠ¨è®¡ç®—å¹³å‡å€¼ä»¥é¿å…å¹¶è¡Œä¸­çš„ä¸€äº›é—®é¢˜
        window_sum = 0.0
        for j in range(window.size):
            window_sum += window[j]
        result[i] = window_sum / window.size
    return result

# æ€§èƒ½æµ‹è¯•
window_size = 50

# é¢„çƒ­Numbaå‡½æ•°ï¼ˆJITç¼–è¯‘ï¼‰
_ = calculate_moving_average_numba(np.random.rand(100), 10)
_ = calculate_moving_average_numba_parallel(np.random.rand(100), 10)

# æµ‹è¯•Pythonç‰ˆæœ¬
start_time = time.time()
python_result = calculate_moving_average_python(data[:10000], window_size)
python_time = time.time() - start_time
print(f"Pythonç‰ˆæœ¬è€—æ—¶: {python_time:.6f} ç§’ (ä»…æµ‹è¯•10000ä¸ªæ•°æ®ç‚¹)")

# æµ‹è¯•NumPyç‰ˆæœ¬
start_time = time.time()
numpy_result = calculate_moving_average_numpy(data, window_size)
numpy_time = time.time() - start_time
print(f"NumPyç‰ˆæœ¬è€—æ—¶: {numpy_time:.6f} ç§’")

# æµ‹è¯•Numbaç‰ˆæœ¬
start_time = time.time()
numba_result = calculate_moving_average_numba(data, window_size)
numba_time = time.time() - start_time
print(f"Numbaç‰ˆæœ¬è€—æ—¶: {numba_time:.6f} ç§’")

# æµ‹è¯•Numbaå¹¶è¡Œç‰ˆæœ¬
start_time = time.time()
numba_parallel_result = calculate_moving_average_numba_parallel(data, window_size)
numba_parallel_time = time.time() - start_time
print(f"Numbaå¹¶è¡Œç‰ˆæœ¬è€—æ—¶: {numba_parallel_time:.6f} ç§’")

# éªŒè¯ç»“æœæ­£ç¡®æ€§
print(f"\nç»“æœéªŒè¯:")
print(f"NumPyä¸Numbaç»“æœæ˜¯å¦ä¸€è‡´: {np.allclose(numpy_result, numba_result)}")
print(f"NumPyä¸Numbaå¹¶è¡Œç»“æœæ˜¯å¦ä¸€è‡´: {np.allclose(numpy_result, numba_parallel_result)}")

# å¼‚å¸¸æ£€æµ‹ç®—æ³•åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®ç°

# 1. Z-Scoreå¼‚å¸¸æ£€æµ‹
@njit
def zscore_detection(data, threshold=3.0):
    """ä½¿ç”¨Z-Scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
    # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
    mean_val = np.mean(data)
    std_val = np.std(data)
    
    # é¿å…é™¤ä»¥é›¶
    if std_val == 0:
        return np.zeros_like(data, dtype=np.bool_)
    
    # è®¡ç®—Z-Score
    z_scores = np.abs((data - mean_val) / std_val)
    
    # æ ‡è®°å¼‚å¸¸å€¼
    return z_scores > threshold

# 2. ç§»åŠ¨å¹³å‡å¼‚å¸¸æ£€æµ‹
@njit
def moving_average_detection(data, window_size=50, threshold=2.0):
    """ä½¿ç”¨ç§»åŠ¨å¹³å‡å’Œç§»åŠ¨æ ‡å‡†å·®æ£€æµ‹å¼‚å¸¸"""
    n = len(data)
    is_anomaly = np.zeros(n, dtype=np.bool_)
    
    # é¢„å…ˆè®¡ç®—ç§»åŠ¨å‡å€¼å’Œç§»åŠ¨æ ‡å‡†å·®
    for i in range(n):
        window_start = max(0, i - window_size + 1)
        window = data[window_start:i+1]
        
        if len(window) < 10:  # è‡³å°‘éœ€è¦10ä¸ªæ•°æ®ç‚¹
            continue
        
        mean_val = np.mean(window)
        std_val = np.std(window)
        
        if std_val > 0:  # é¿å…é™¤ä»¥é›¶
            # è®¡ç®—å½“å‰å€¼ä¸ç§»åŠ¨å‡å€¼çš„åå·®
            deviation = abs(data[i] - mean_val) / std_val
            is_anomaly[i] = deviation > threshold
    
    return is_anomaly

# 3. IQRï¼ˆå››åˆ†ä½è·ï¼‰å¼‚å¸¸æ£€æµ‹
@njit
def iqr_detection(data, threshold=1.5):
    """ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
    # è®¡ç®—å››åˆ†ä½æ•°
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    iqr = q3 - q1
    
    # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
    lower_bound = q1 - threshold * iqr
    upper_bound = q3 + threshold * iqr
    
    # æ ‡è®°å¼‚å¸¸å€¼
    return (data < lower_bound) | (data > upper_bound)

# æµ‹è¯•å¼‚å¸¸æ£€æµ‹ç®—æ³•
# ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆåŒ…å«ä¸€äº›å¼‚å¸¸å€¼ï¼‰
def generate_test_data(size=1000, anomaly_count=5):
    # æ­£å¸¸æ•°æ®ï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰
    data = np.random.normal(loc=25, scale=2, size=size)
    
    # æ·»åŠ å¼‚å¸¸å€¼
    anomaly_indices = np.random.choice(size, anomaly_count, replace=False)
    for idx in anomaly_indices:
        # éšæœºé€‰æ‹©æ˜¯æ·»åŠ æé«˜å€¼è¿˜æ˜¯æä½å€¼
        if np.random.random() > 0.5:
            data[idx] = data[idx] + np.random.uniform(10, 20)
        else:
            data[idx] = data[idx] - np.random.uniform(10, 20)
    
    return data, anomaly_indices

# ç”Ÿæˆæµ‹è¯•æ•°æ®
test_data, true_anomalies = generate_test_data()

# è¿è¡Œå¼‚å¸¸æ£€æµ‹
zscore_anomalies = zscore_detection(test_data)
moving_avg_anomalies = moving_average_detection(test_data)
iqr_anomalies = iqr_detection(test_data)

# è¯„ä¼°æ£€æµ‹æ€§èƒ½
def evaluate_detection(true_indices, detected):
    """è¯„ä¼°å¼‚å¸¸æ£€æµ‹ç®—æ³•æ€§èƒ½"""
    # è®¡ç®—çœŸé˜³æ€§ã€å‡é˜³æ€§ã€å‡é˜´æ€§
    true_positive = 0
    false_positive = 0
    false_negative = 0
    
    # åˆ›å»ºçœŸå®å¼‚å¸¸å€¼çš„é›†åˆ
    true_set = set(true_indices)
    
    # éå†æ£€æµ‹ç»“æœ
    for i in range(len(detected)):
        if detected[i]:
            if i in true_set:
                true_positive += 1
            else:
                false_positive += 1
        elif i in true_set:
            false_negative += 1
    
    # è®¡ç®—å‡†ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°
    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0
    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        "true_positive": true_positive,
        "false_positive": false_positive,
        "false_negative": false_negative,
        "precision": precision,
        "recall": recall,
        "f1_score": f1_score
    }

# è¯„ä¼°ç®—æ³•
zscore_metrics = evaluate_detection(true_anomalies, zscore_anomalies)
moving_avg_metrics = evaluate_detection(true_anomalies, moving_avg_anomalies)
iqr_metrics = evaluate_detection(true_anomalies, iqr_anomalies)

print("\nå¼‚å¸¸æ£€æµ‹ç®—æ³•è¯„ä¼°:")
print("Z-Score æ–¹æ³•:")
print(json.dumps(zscore_metrics, indent=2))
print("\nç§»åŠ¨å¹³å‡æ–¹æ³•:")
print(json.dumps(moving_avg_metrics, indent=2))
print("\nIQR æ–¹æ³•:")
print(json.dumps(iqr_metrics, indent=2))

# ä½¿ç”¨Redisè¿›è¡Œè¾¹ç¼˜è®¾å¤‡æ•°æ®ç¼“å­˜å’Œå…±äº«

# å®‰è£…: pip install redis

import redis

class EdgeDataCache:
    def __init__(self, host='localhost', port=6379, db=0):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            self.redis_client = redis.Redis(host=host, port=port, db=db)
            # æµ‹è¯•è¿æ¥
            self.redis_client.ping()
            print(f"å·²è¿æ¥åˆ°RedisæœåŠ¡å™¨: {host}:{port}")
            self.connected = True
        except redis.ConnectionError:
            print(f"æ— æ³•è¿æ¥åˆ°RedisæœåŠ¡å™¨: {host}:{port}")
            print("å°†ä½¿ç”¨å†…å­˜ç¼“å­˜ä½œä¸ºå¤‡é€‰")
            self.redis_client = None
            self.connected = False
            # ä½¿ç”¨Pythonå­—å…¸ä½œä¸ºå†…å­˜ç¼“å­˜
            self.memory_cache = {}
    
    def store_sensor_data(self, device_id, sensor_type, data, expire_seconds=3600):
        """å­˜å‚¨ä¼ æ„Ÿå™¨æ•°æ®"""
        key = f"sensor:{device_id}:{sensor_type}"
        
        # å°†æ•°æ®åºåˆ—åŒ–ä¸ºJSON
        json_data = json.dumps(data)
        
        if self.connected:
            try:
                # å­˜å‚¨æ•°æ®å¹¶è®¾ç½®è¿‡æœŸæ—¶é—´
                self.redis_client.setex(key, expire_seconds, json_data)
                return True
            except Exception as e:
                print(f"Rediså­˜å‚¨é”™è¯¯: {e}")
                # å›é€€åˆ°å†…å­˜ç¼“å­˜
                self.memory_cache[key] = (json_data, time.time() + expire_seconds)
                return True
        else:
            # ä½¿ç”¨å†…å­˜ç¼“å­˜
            self.memory_cache[key] = (json_data, time.time() + expire_seconds)
            return True
    
    def get_sensor_data(self, device_id, sensor_type):
        """è·å–ä¼ æ„Ÿå™¨æ•°æ®"""
        key = f"sensor:{device_id}:{sensor_type}"
        
        if self.connected:
            try:
                # ä»Redisè·å–æ•°æ®
                data = self.redis_client.get(key)
                if data:
                    return json.loads(data)
                return None
            except Exception as e:
                print(f"Redisè¯»å–é”™è¯¯: {e}")
                # å›é€€åˆ°å†…å­˜ç¼“å­˜
                return self._get_from_memory_cache(key)
        else:
            # ä»å†…å­˜ç¼“å­˜è·å–
            return self._get_from_memory_cache(key)
    
    def _get_from_memory_cache(self, key):
        """ä»å†…å­˜ç¼“å­˜è·å–æ•°æ®"""
        if key in self.memory_cache:
            data, expire_time = self.memory_cache[key]
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() < expire_time:
                return json.loads(data)
            else:
                # åˆ é™¤è¿‡æœŸæ•°æ®
                del self.memory_cache[key]
        return None
    
    def store_time_series_data(self, device_id, metric, timestamp, value):
        """å­˜å‚¨æ—¶é—´åºåˆ—æ•°æ®"""
        key = f"timeseries:{device_id}:{metric}"
        
        if self.connected:
            try:
                # ä½¿ç”¨Redisçš„æœ‰åºé›†åˆå­˜å‚¨æ—¶é—´åºåˆ—
                self.redis_client.zadd(key, {json.dumps({"value": value}): timestamp})
                # ä¿ç•™æœ€è¿‘1000ä¸ªæ•°æ®ç‚¹
                self.redis_client.zremrangebyrank(key, 0, -1001)
                return True
            except Exception as e:
                print(f"Redisæ—¶é—´åºåˆ—å­˜å‚¨é”™è¯¯: {e}")
                return False
        else:
            # ç®€åŒ–çš„å†…å­˜å­˜å‚¨ï¼ˆä»…ä¿å­˜æœ€æ–°å€¼ï¼‰
            mem_key = f"{key}:latest"
            self.memory_cache[mem_key] = (json.dumps({"timestamp": timestamp, "value": value}), float('inf'))
            return True
    
    def get_time_series_data(self, device_id, metric, start_time=None, end_time=None, limit=100):
        """è·å–æ—¶é—´åºåˆ—æ•°æ®"""
        key = f"timeseries:{device_id}:{metric}"
        
        if self.connected:
            try:
                # è®¾ç½®èŒƒå›´
                min_score = start_time if start_time else -
                max_score = end_time if end_time else +
                
                # è·å–æ•°æ®
                data = self.redis_client.zrangebyscore(key, min_score, max_score, withscores=True, start=0, num=limit)
                
                # è§£æç»“æœ
                result = []
                for value_data, timestamp in data:
                    value_dict = json.loads(value_data)
                    result.append({
                        "timestamp": timestamp,
                        "value": value_dict["value"]
                    })
                
                return result
            except Exception as e:
                print(f"Redisæ—¶é—´åºåˆ—è¯»å–é”™è¯¯: {e}")
                # å°è¯•è¿”å›æœ€æ–°å€¼
                mem_key = f"{key}:latest"
                latest_data = self._get_from_memory_cache(mem_key)
                return [latest_data] if latest_data else []
        else:
            # è¿”å›å†…å­˜ä¸­çš„æœ€æ–°å€¼
            mem_key = f"{key}:latest"
            latest_data = self._get_from_memory_cache(mem_key)
            return [latest_data] if latest_data else []
    
    def clear_device_data(self, device_id):
        """æ¸…é™¤ç‰¹å®šè®¾å¤‡çš„æ‰€æœ‰æ•°æ®"""
        if self.connected:
            try:
                # è·å–æ‰€æœ‰ç›¸å…³é”®
                pattern = f"*:{device_id}:*"
                keys = self.redis_client.keys(pattern)
                if keys:
                    self.redis_client.delete(*keys)
                return True
            except Exception as e:
                print(f"Redisæ¸…é™¤é”™è¯¯: {e}")
                return False
        else:
            # æ¸…ç†å†…å­˜ç¼“å­˜
            keys_to_delete = []
            for key in self.memory_cache:
                if f":{device_id}:" in key:
                    keys_to_delete.append(key)
            
            for key in keys_to_delete:
                del self.memory_cache[key]
            
            return True

# ä½¿ç”¨ç¤ºä¾‹
# cache = EdgeDataCache()
# 
# # å­˜å‚¨ä¼ æ„Ÿå™¨æ•°æ®
# sensor_data = {
#     "value": 26.5,
#     "timestamp": time.time(),
#     "unit": "Â°C"
# }
# cache.store_sensor_data("device_01", "temperature", sensor_data)
# 
# # è·å–ä¼ æ„Ÿå™¨æ•°æ®
# retrieved_data = cache.get_sensor_data("device_01", "temperature")
# print(f"\næ£€ç´¢åˆ°çš„æ•°æ®: {retrieved_data}")
# 
# # å­˜å‚¨æ—¶é—´åºåˆ—æ•°æ®
# for i in range(10):
#     timestamp = time.time() - (10 - i) * 60  # è¿‡å»10åˆ†é’Ÿçš„æ•°æ®ï¼Œæ¯åˆ†é’Ÿä¸€ä¸ªç‚¹
#     value = 25 + i * 0.5  # ä»25åº¦å¼€å§‹ï¼Œæ¯åˆ†é’Ÿå¢åŠ 0.5åº¦
#     cache.store_time_series_data("device_01", "temperature", timestamp, value)
# 
# # è·å–æ—¶é—´åºåˆ—æ•°æ®
# time_series_data = cache.get_time_series_data("device_01", "temperature", limit=5)
# print(f"\nè·å–çš„æ—¶é—´åºåˆ—æ•°æ®:")
# for point in time_series_data:
#     print(f"  æ—¶é—´: {point['timestamp']}, å€¼: {point['value']}")
```

## 3. ä½ä»£ç ä¸æ— ä»£ç å¼€å‘

### 3.1 Pythonä½ä»£ç å¹³å°ä¸æ¡†æ¶
**[æ ‡è¯†: LOWCODE-FRAMEWORK-001]**

Pythoné©±åŠ¨çš„ä½ä»£ç å¼€å‘å¹³å°å’Œæ¡†æ¶çš„ä½¿ç”¨æŒ‡å—ã€‚

```python
# ä½¿ç”¨Streamlitå¿«é€Ÿæ„å»ºWebåº”ç”¨

# å®‰è£…: pip install streamlit pandas matplotlib plotly

"""
ä½¿ç”¨æ–¹æ³•ï¼š
1. å°†ä»¥ä¸‹ä»£ç ä¿å­˜ä¸º app.py
2. è¿è¡Œ: streamlit run app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¯è§†åŒ–ä»ªè¡¨æ¿",
    page_icon="ğŸ“Š",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("äº¤äº’å¼æ•°æ®å¯è§†åŒ–ä»ªè¡¨æ¿")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("è®¾ç½®")
    
    # é€‰æ‹©æ•°æ®æº
    data_source = st.radio(
        "é€‰æ‹©æ•°æ®æº",
        ("ä½¿ç”¨ç¤ºä¾‹æ•°æ®", "ä¸Šä¼ CSVæ–‡ä»¶")
    )
    
    # ä¸Šä¼ æ–‡ä»¶é€‰é¡¹
    uploaded_file = None
    if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
    
    # å›¾è¡¨ç±»å‹é€‰æ‹©
    chart_type = st.selectbox(
        "é€‰æ‹©å›¾è¡¨ç±»å‹",
        ("æŠ˜çº¿å›¾", "æŸ±çŠ¶å›¾", "æ•£ç‚¹å›¾", "çƒ­åŠ›å›¾", "ç®±çº¿å›¾")
    )
    
    # é¢œè‰²ä¸»é¢˜
    theme = st.select_slider(
        "é€‰æ‹©é¢œè‰²ä¸»é¢˜",
        options=["é»˜è®¤", "æ˜äº®", "æš—è‰²", "å½©è‰²"]
    )

# ç”Ÿæˆæˆ–åŠ è½½æ•°æ®
if data_source == "ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    dates = pd.date_range(start="2023-01-01", end="2023-12-31", freq="D")
    
    # åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªæŒ‡æ ‡çš„DataFrame
    data = pd.DataFrame({
        "æ—¥æœŸ": dates,
        "é”€å”®é¢": np.random.normal(1000, 200, len(dates)),
        "è®¿é—®é‡": np.random.normal(5000, 1000, len(dates)),
        "è½¬åŒ–ç‡": np.random.normal(0.05, 0.01, len(dates)),
        "å®¢å•ä»·": np.random.normal(200, 50, len(dates))
    })
    
    # æ·»åŠ ä¸€äº›åˆ†ç±»æ•°æ®
    categories = ["ç”µå­äº§å“", "æœè£…", "é£Ÿå“", "å®¶å±…", "ä¹¦ç±"]
    data["ç±»åˆ«"] = np.random.choice(categories, size=len(dates))
    
    st.info("ä½¿ç”¨äº†ç¤ºä¾‹é”€å”®æ•°æ®")
else:
    if uploaded_file is not None:
        try:
            data = pd.read_csv(uploaded_file)
            st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            st.subheader("æ•°æ®é¢„è§ˆ")
            st.dataframe(data.head())
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            st.stop()
    else:
        st.warning("è¯·ä¸Šä¼ CSVæ–‡ä»¶")
        st.stop()

# æ•°æ®å¤„ç†åŒºåŸŸ
st.subheader("æ•°æ®ç»Ÿè®¡ä¿¡æ¯")

# æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
col1, col2 = st.columns(2)
with col1:
    st.write("æ•°æ®ç»´åº¦:")
    st.info(f"è¡Œæ•°: {data.shape[0]}, åˆ—æ•°: {data.shape[1]}")
    
with col2:
    st.write("æ•°å€¼åˆ—ç»Ÿè®¡:")
    st.dataframe(data.describe())

# äº¤äº’å¼æ•°æ®é€‰æ‹©å™¨
st.subheader("æ•°æ®ç­›é€‰")

# ä¸ºæ•°å€¼åˆ—åˆ›å»ºç­›é€‰å™¨
numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
selected_cols = st.multiselect(
    "é€‰æ‹©è¦åˆ†æçš„æ•°å€¼åˆ—",
    options=numeric_cols,
    default=numeric_cols[:2] if numeric_cols else []
)

# ä¸ºåˆ†ç±»åˆ—åˆ›å»ºç­›é€‰å™¨
cat_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
if cat_cols:
    selected_cat_col = st.selectbox(
        "é€‰æ‹©åˆ†ç±»åˆ—",
        options=cat_cols
    )
    
    if selected_cat_col:
        unique_cats = data[selected_cat_col].unique()
        selected_cats = st.multiselect(
            f"é€‰æ‹©{selected_cat_col}çš„ç±»åˆ«",
            options=unique_cats,
            default=list(unique_cats[:3]) if len(unique_cats) > 3 else list(unique_cats)
        )
        
        # åº”ç”¨åˆ†ç±»ç­›é€‰
        if selected_cats:
            data = data[data[selected_cat_col].isin(selected_cats)]

# ç»˜åˆ¶å›¾è¡¨
st.subheader("æ•°æ®å¯è§†åŒ–")

# æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸåˆ—ç”¨äºæ—¶é—´åºåˆ—
if any(data.columns.str.contains('æ—¥æœŸ|date|time', case=False)):
    date_col = [col for col in data.columns if any(x in col.lower() for x in ['æ—¥æœŸ', 'date', 'time'])][0]
    data[date_col] = pd.to_datetime(data[date_col])
    
    # æ—¶é—´èŒƒå›´é€‰æ‹©
    min_date = data[date_col].min().date()
    max_date = data[date_col].max().date()
    
    start_date, end_date = st.date_input(
        "é€‰æ‹©æ—¥æœŸèŒƒå›´",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )
    
    # åº”ç”¨æ—¥æœŸç­›é€‰
    data = data[(data[date_col].dt.date >= start_date) & (data[date_col].dt.date <= end_date)]

# æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹è¿›è¡Œå¯è§†åŒ–
if selected_cols and not data.empty:
    if chart_type == "æŠ˜çº¿å›¾":
        fig = go.Figure()
        for col in selected_cols:
            fig.add_trace(go.Scatter(
                x=data[date_col] if 'date_col' in locals() else data.index,
                y=data[col],
                mode='lines',
                name=col
            ))
        
        fig.update_layout(
            title="æ—¶é—´åºåˆ—æŠ˜çº¿å›¾",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="å€¼",
            legend_title="æŒ‡æ ‡"
        )
        
    elif chart_type == "æŸ±çŠ¶å›¾":
        # æŒ‰ç±»åˆ«åˆ†ç»„ç»Ÿè®¡
        if 'selected_cat_col' in locals() and selected_cat_col:
            grouped_data = data.groupby(selected_cat_col)[selected_cols].mean().reset_index()
            fig = px.bar(
                grouped_data,
                x=selected_cat_col,
                y=selected_cols,
                barmode='group',
                title=f"æŒ‰{selected_cat_col}åˆ†ç»„çš„æŸ±çŠ¶å›¾"
            )
        else:
            # ç®€å•æŸ±çŠ¶å›¾
            fig = go.Figure()
            for col in selected_cols:
                fig.add_trace(go.Bar(
                    x=data.index[:50],  # åªæ˜¾ç¤ºå‰50ä¸ªæ•°æ®ç‚¹
                    y=data[col][:50],
                    name=col
                ))
            fig.update_layout(title="æŸ±çŠ¶å›¾", xaxis_title="ç´¢å¼•", yaxis_title="å€¼")
    
    elif chart_type == "æ•£ç‚¹å›¾":
        if len(selected_cols) >= 2:
            fig = px.scatter(
                data,
                x=selected_cols[0],
                y=selected_cols[1],
                color=selected_cat_col if 'selected_cat_col' in locals() and selected_cat_col else None,
                size=selected_cols[2] if len(selected_cols) > 2 else None,
                hover_data=data.columns,
                title="æ•£ç‚¹å›¾"
            )
        else:
            st.warning("æ•£ç‚¹å›¾éœ€è¦è‡³å°‘ä¸¤åˆ—æ•°æ®")
            st.stop()
    
    elif chart_type == "çƒ­åŠ›å›¾":
        # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
        corr_matrix = data[selected_cols].corr()
        fig = px.imshow(
            corr_matrix,
            text_auto=True,
            aspect="auto",
            title="ç›¸å…³æ€§çƒ­åŠ›å›¾"
        )
    
    elif chart_type == "ç®±çº¿å›¾":
        fig = go.Figure()
        for col in selected_cols:
            fig.add_trace(go.Box(
                y=data[col],
                name=col,
                boxpoints='all'
            ))
        fig.update_layout(title="ç®±çº¿å›¾", yaxis_title="å€¼")
    
    # è®¾ç½®ä¸»é¢˜
    if theme == "æš—è‰²":
        fig.update_layout(template="plotly_dark")
    elif theme == "æ˜äº®":
        fig.update_layout(template="plotly_white")
    elif theme == "å½©è‰²":
        fig.update_layout(template="plotly_express_colorway")
    
    # æ˜¾ç¤ºå›¾è¡¨
    st.plotly_chart(fig, use_container_width=True)
    
    # æä¾›ä¸‹è½½é€‰é¡¹
    st.download_button(
        label="ä¸‹è½½å›¾è¡¨ä¸ºPNG",
        data=fig.to_image(format="png"),
        file_name="chart.png",
        mime="image/png"
    )
else:
    st.warning("è¯·é€‰æ‹©è¦åˆ†æçš„åˆ—æˆ–ä¸Šä¼ æœ‰æ•ˆæ•°æ®")

# æ•°æ®å¯¼å‡ºåŒºåŸŸ
st.subheader("æ•°æ®å¯¼å‡º")

# æä¾›æ•°æ®å¯¼å‡ºé€‰é¡¹
if st.button("å¯¼å‡ºç­›é€‰åçš„æ•°æ®ä¸ºCSV"):
    csv = data.to_csv(index=False)
    st.download_button(
        label="ä¸‹è½½CSVæ–‡ä»¶",
        data=csv,
        file_name="filtered_data.csv",
        mime="text/csv"
    )

# ä½¿ç”¨Dashæ„å»ºäº¤äº’å¼Webåº”ç”¨

"""
# å®‰è£…: pip install dash dash-bootstrap-components pandas plotly

from dash import Dash, dcc, html, Input, Output, callback
import dash_bootstrap_components as dbc
import pandas as pd
import numpy as np
import plotly.express as px

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
np.random.seed(42)
dates = pd.date_range(start="2023-01-01", end="2023-12-31", freq="D")
data = pd.DataFrame({
    "æ—¥æœŸ": dates,
    "é”€å”®é¢": np.random.normal(1000, 200, len(dates)),
    "è®¿é—®é‡": np.random.normal(5000, 1000, len(dates)),
    "è½¬åŒ–ç‡": np.random.normal(0.05, 0.01, len(dates)),
    "å®¢å•ä»·": np.random.normal(200, 50, len(dates)),
    "ç±»åˆ«": np.random.choice(["ç”µå­äº§å“", "æœè£…", "é£Ÿå“", "å®¶å±…", "ä¹¦ç±"], size=len(dates))
})

# åˆ›å»ºDashåº”ç”¨
app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# åº”ç”¨å¸ƒå±€
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.H1("äº¤äº’å¼æ•°æ®åˆ†æä»ªè¡¨æ¿"), className="mb-4 mt-4")
    ]),
    
    dbc.Row([
        dbc.Col([
            html.H5("è®¾ç½®"),
            html.Label("é€‰æ‹©æŒ‡æ ‡"),
            dcc.Dropdown(
                id='metric-dropdown',
                options=[
                    {'label': 'é”€å”®é¢', 'value': 'é”€å”®é¢'},
                    {'label': 'è®¿é—®é‡', 'value': 'è®¿é—®é‡'},
                    {'label': 'è½¬åŒ–ç‡', 'value': 'è½¬åŒ–ç‡'},
                    {'label': 'å®¢å•ä»·', 'value': 'å®¢å•ä»·'}
                ],
                value='é”€å”®é¢',
                clearable=False
            ),
            
            html.Label("é€‰æ‹©ç±»åˆ«", className="mt-3"),
            dcc.Checklist(
                id='category-checklist',
                options=[
                    {'label': 'ç”µå­äº§å“', 'value': 'ç”µå­äº§å“'},
                    {'label': 'æœè£…', 'value': 'æœè£…'},
                    {'label': 'é£Ÿå“', 'value': 'é£Ÿå“'},
                    {'label': 'å®¶å±…', 'value': 'å®¶å±…'},
                    {'label': 'ä¹¦ç±', 'value': 'ä¹¦ç±'}
                ],
                value=["ç”µå­äº§å“", "æœè£…", "é£Ÿå“"],
                inline=True
            ),
            
            html.Label("é€‰æ‹©æ—¶é—´èŒƒå›´", className="mt-3"),
            dcc.DatePickerRange(
                id='date-range',
                start_date=data["æ—¥æœŸ"].min(),
                end_date=data["æ—¥æœŸ"].max(),
                display_format='YYYY-MM-DD'
            )
        ], width=3),
        
        dbc.Col([
            dcc.Graph(id='time-series-chart')
        ], width=9)
    ]),
    
    dbc.Row([
        dbc.Col([
            dcc.Graph(id='distribution-chart')
        ], width=6),
        
        dbc.Col([
            dcc.Graph(id='category-chart')
        ], width=6)
    ], className="mt-4")
], fluid=True)

# å›è°ƒå‡½æ•° - æ›´æ–°æ—¶é—´åºåˆ—å›¾è¡¨
@app.callback(
    Output('time-series-chart', 'figure'),
    [Input('metric-dropdown', 'value'),
     Input('category-checklist', 'value'),
     Input('date-range', 'start_date'),
     Input('date-range', 'end_date')]
)
def update_time_series(selected_metric, selected_categories, start_date, end_date):
    # ç­›é€‰æ•°æ®
    filtered_data = data[
        (data['ç±»åˆ«'].isin(selected_categories)) &
        (data['æ—¥æœŸ'] >= start_date) &
       